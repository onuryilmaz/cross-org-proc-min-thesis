\chapter{RESULTS AND DISCUSSIONS}
\label{chp:results-and-discussions}

In this chapter, methodology presented in this thesis study is applied on datasets and results are presented. Firstly, evaluation metrics are defined for each stage of methodology to evaluate performance of approach. 

In this chapter, methodology proposed in this thesis study is presented. Firstly, approach overview is described from a high-level perspective. Then, each stage in the methodology is presented together with their importance in the study, mathematical representations and definitions; and black-box diagrams. In the last section of this chapter, implementation details of this methodology in ProM framework is explained in detail with a software architecture overview.



\section{Evaluation Metrics}
\label{sec:evaluation-metrics}
Approach in this study is an aggregation of various methods and they are significantly different from each other in their mathematical background. Therefore, instead of a global evaluation metric for the complete methodology, each stage will be evaluated within its evaluation metrics. Since these stages are executed sequentially, it is important for each stage to perform enough well to yield a successful outcome. In this section, evaluation metrics for each stage will be presented and they will be used to determine the success of methodology on experiments.

\subsection{Process Model Mining}
\label{subsec:process-model-mining-eval}
Process model mining stage takes input as event logs of organizations and creates process models using process mining algorithms, namely \textit{Inductive Miner} \cite{leemans2014discoveringinfrequent}. Performance of this stage can be measured by the conformance of the process models to the the event logs. Four competing quality criteria are defined in \cite{van2011process} and they are \textit{fitness}, \textit{simplicity}, \textit{precision} and \textit{generalization}. Fitness is based on the idea of being able to replay event log over process model whereas precision focuses not underfitting the event log. Simplicity idea is based on the fact that the simplest model is the best model, on the other hand generalization supports not overfitting the event logs. These four competing criteria are mathematically defined in \cite{rozinat2008conformance} and grouped into two dimensions for analysis purposes:

\begin{description}
  \item[Fitness] Event log and the process model should \textit{fit} to each other, in other words process model should be able to parse the event log. 
  \item[Appropriateness] Since \textit{fitness} does not provide information about the meaningfulness of process models, this dimension is defined. Two notions comprise this idea; \textit{Structural Appropriateness} considers the simplicity whereas \textit{Behavioral Appropriateness} analyzes balance between overfitting and underfitting.
\end{description}

In this thesis study, process model mining stage will be evaluated by the \textit{Fitness} and \textit{Appropriateness} of the mined process models for each organization. In ProM  It is expected to have higher \textit{fitness}, closer to 1, and a high level of appropriateness to continue to the next stages with the high quality process models. While evaluating, \textit{fitness} will be more dominant since \textit{appropriateness} without \textit{fitness} means less.

%	conformance plugin'i çağır, filtre ekranında var, 
%	structural olanı elle hesapla -> http://wwwis.win.tue.nl/~wvdaalst/publications/p436.pdf pg21

\subsection{Performance Indicator Analysis}
\label{subsec:performance-indicator-analysis-eval}
Performance indicator analysis stage consists of two parts as replaying event logs over process models and clustering organizations based on the performance indicators. In the replay phase, main operation is to \textit{align} \cite{van2012replaying} event logs and process models. This alignment is the based on the idea of finding the optimal alignment where total cost of \textit{move on process model} and \textit{move on event log} are minimized. Since there is no baseline information for alignment costs of organizational logs, total cost information will be used together with the process model mining evaluation metrics. In other words, for the event logs and process models with known conformance metrics, total cost of alignments will create a secondary check if there are any problems related to replaying events over process models. It is expected to have less total cost of alignment for the organizations with higher conformance since it is easy to align event logs and processes with high superior fitness values.

% Şu pluginle bak: Check compliance using conformance checking ->

For the second stage of performance indicator analysis, there is a need to evaluate performance of clustering organizations. In this stage, organizations are clustered  based on their performance indicator values that are calculated over replaying. Since there is no labeled data in the context of this thesis study, any cross-validation techniques could not be applied and thus internal evaluation metrics are exploited. As mentioned in the Section~\ref{subsec:performance-indicator-clustering}, within SSE values between clusters are plotted to the end user to select an appropriate number of clusters. It is expected that within SSE values decreases as number of clusters increases; however, number of clusters should be selected without causing overfitting.

% clustering evaluation
% wekadan gelen within sse 
 

\subsection{Mismatch Pattern Analysis}
\label{subsec:mismatch-pattern-analysis-eval}
Mismatch pattern analysis stage aims to find differences between the process models of different organizations. In this thesis study mismatch patterns defined in \cite{dijkman2007mismatch} are mathematically defined and analyzers are developed to locate these patterns. At the time of this study, it is known to be first to use mismatch patterns in a generic method, therefore evaluation is based on comparing with well-defined prior similarity metrics.

Structural similarity between process models is presented in \cite{dijkman2011similarity} by the \textit{graph-edit distance} notion. In graph theory, \textit{graph-edit distance} is the minimum number of \textit{graph-edit operations} necessary to get one from graph to another. In the process mining field, \textit{graph-edit operations} are simply node addition, deletion or substitution. In the study \cite{dijkman2011similarity}, both \textit{graph-edit distance} and \textit{graph-edit similarity} definitions are provided with their mathematical background. In this study, mismatch pattern analysis stage is evaluated by comparing the number of mismatch patterns and the \textit{graph-edit similarity} of process models. Without any performance indicator clustering, it is expected to have larger number of mismatch patterns when the similarity between process models is low. This will ensure the performance and suitability using mismatch pattern analysis instead in the methodology.

 % BartHompes paketi ile ikili ikili çalıştır- run

\subsection{Recommendation Generation}
\label{subsec:recommendation-generation-eval}
In the recommendation generation stage, set of mismatch patterns are presented to the end user based on the selected organization and performance difference threshold. This stage aims to list whole mismatch patterns that can cause the other organizations perform better than a difference threshold. Idea of using performance threshold should be evaluated in this stage with its responsiveness. In other words, it is expected that this stage will help the end user to focus on the most important performance improvements for the organization analyzed. Therefore, different threshold values will be tried to check how many mismatch patterns are generated for organizations and how they could be used for focused analysis. In addition, quality and applicability of the recommendations should be analyzed and this requires a high level of knowledge starting from the collecting event logs in the organizations. This knowledge should include know-how about process changes, domain knowledge about the field of organizations' activity and structural attributions of the organizations.


\section{Dataset Selection}
\label{sec:dataset-selection}
Cross-organizational mining aims to find cross-correlation of workflows and activities in different organizations and this yields the necessity of organizations that do the same main activity with a comparable process flows. In business life, this includes aligning the tasks from different organizations with different business needs, priorities and organizational structures and culture. Considering these characteristics, there are few dataset available in the literature that are well-structured, documented and valuable. In this thesis study, one synthetic and one real-life event log datasets  are presented and used in the following sections to evaluate the performance of the proposed methodology.

\begin{description}
  \item[Loan Application Process \cite{ec392c32-4620-44ac-9b8c-e48890e4bcfa}] This synthetically created event log describes the process of a simple loan application in a financial institute. In summary, a customer fills a form and starts a request over website and it starts the different approaches of variants in different organizations that ends with notifying the customer about the acceptance of application. This dataset includes artificial event logs of 4 variants where each variant includes different sets of approaches such as parallelism, choices and sequential tasks. These event logs are used to test different approaches of discovering a configurable process model from a collection of event logs in study \cite{buijs2014flexible}.
  \item[Environmental Permit Application Process \cite{ae6fb88e-1b85-4a11-94e4-ff9ac5b1fe0a}] This dataset originates from the Configurable Services for Local Governments (CoSeLoG) project \cite{van2011business} which investigates the similarities and dissimilarities between several processes of different municipalities in the Netherlands.  Dataset contains the records of the execution of the receiving phase of the building permit application process in 5 municipalities, which are comparable since activity labels in the different event logs refer to the same activities performed in the five municipalities. This data set is also mentioned in the literature as \textit{\"Processing applications for building and/or environmental permits ('Wet Algemene Bepalingen omgevingsrecht (WABO)' in Dutch)\"}.

  When the organizations that have similar processes are considered, municipalities are one of the prominent candidates. In Netherlands there are more than 400 municipalities and they offer between 400 and 500 different products and services with their own processes. Unlike corporations, municipalities have the advantage that they can seek for collaboration since they are not direct competitions \cite{buijs2012towards} and this advantage makes them valuable for cross-organizational analysis. CoSeLoG research project aims to develop a shared business process management system within a shared Software-as-a-Service environment using the commonalities between the processes of municipalities \cite{buijs2014flexible}. In the scope of CoSeLoG research, five different processes of municipalities are analyzed and at the time of this thesis study only \textit{Environmental Permit Application Process} dataset is publicly shared in the literature.
\end{description}


\section{Loan Application Process}
\label{sec:environmental-permit-application-process}
In this section, methodology proposed in this thesis study will be applied on the \textit{Loan Application Process} dataset \cite{ec392c32-4620-44ac-9b8c-e48890e4bcfa} and evaluation results will be presented. Statistical information about this dataset can be tabulated in ...

* Event log statistics
* Methodology Stages
* Results


\section{Environmental Permit Application Process}
\label{sec:environmental-permit-application-process}
 
* Event log statistics
* Methodology Stages
* Results

\section{Discussions}
\label{sec:discussions}