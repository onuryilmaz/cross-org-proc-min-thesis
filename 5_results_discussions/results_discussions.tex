\chapter{RESULTS AND DISCUSSIONS}
\label{chp:results-and-discussions}
 

\section{Dataset Selection}
\label{sec:dataset-selection}
 

\section{Evaluation Metrics}
\label{sec:evaluation-metrics}
Approach in this study is an aggregation of various methods and they are significantly different from each other in their mathematical background. Therefore, instead of a global evaluation metric for the complete methodology, each stage will be evaluated within its evaluation metrics. Since these stages are executed sequentially, it is important for each stage to perform enough well to yield a successful outcome. In this section, evaluation metrics for each stage will be presented and they will be used to determine the success of methodology on experiments.

\subsection{Process Model Mining}
\label{subsec:process-model-mining-eval}
Process model mining stage takes input as event logs of organizations and creates process models using process mining algorithms, namely \textit{Inductive Miner} \cite{leemans2014discoveringinfrequent}. Performance of this stage can be measured by the conformance of the process models to the the event logs. Four competing quality criteria are defined in \cite{van2011process} and they are \textit{fitness}, \textit{simplicity}, \textit{precision} and \textit{generalization}. Fitness is based on the idea of being able to replay event log over process model whereas precision focuses not underfitting the event log. Simplicity idea is based on the fact that the simplest model is the best model, on the other hand generalization supports not overfitting the event logs. These four competing criteria are mathematically defined in \cite{rozinat2008conformance} and grouped into two dimensions for analysis purposes:

\begin{description}
  \item[Fitness] Event log and the process model should \textit{fit} to each other, in other words process model should be able to parse the event log. 
  \item[Appropriateness] Since \textit{fitness} does not provide information about the meaningfulness of process models, this dimension is defined. Two notions comprise this idea; \textit{Structural Appropriateness} considers the simplicity whereas \textit{Behavioral Appropriateness} analyzes balance between overfitting and underfitting.
\end{description}

In this thesis study, process model mining stage will be evaluated by the \textit{Fitness} and \textit{Appropriateness} of the mined process models for each organization. In ProM  It is expected to have higher \textit{fitness}, closer to 1, and a high level of appropriateness to continue to the next stages with the high quality process models. While evaluating, \textit{fitness} will be more dominant since \textit{appropriateness} without \textit{fitness} means less.

%	conformance plugin'i çağır, filtre ekranında var, 
%	structural olanı elle hesapla ? yöntem bak

\subsection{Performance Indicator Analysis}
\label{subsec:performance-indicator-analysis-eval}
Performance indicator analysis stage consists of two parts as replaying event logs over process models and clustering organizations based on the performance indicators. In the replay phase, main operation is to \textit{align} \cite{van2012replaying} event logs and process models. This alignment is the based on the idea of finding the optimal alignment where total cost of \textit{move on process model} and \textit{move on event log} are minimized. Since there is no baseline information for alignment costs of organizational logs, total cost information will be used together with the process model mining evaluation metrics. In other words, for the event logs and process models with known conformance metrics, total cost of alignments will create a secondary check if there are any problems related to replaying events over process models. It is expected to have less total cost of alignment for the organizations with higher conformance since it is easy to align event logs and processes with high superior fitness values.

% Şu pluginle bak: Check compliance using conformance checking ->

For the second stage of performance indicator analysis, there is a need to evaluate performance of clustering organizations. In this stage, organizations are clustered  based on their performance indicator values that are calculated over replaying. Since there is no labeled data in the context of this thesis study, any cross-validation techniques could not be applied and thus internal evaluation metrics are exploited. As mentioned in the Section~\ref{subsec:performance-indicator-clustering}, within SSE values between clusters are plotted to the end user to select an appropriate number of clusters. It is expected that within SSE values decreases as number of clusters increases; however, number of clusters should be selected without causing overfitting.

% clustering evaluation
% wekadan gelen within sse 
 

\subsection{Mismatch Pattern Analysis}
\label{subsec:mismatch-pattern-analysis-eval}
Mismatch pattern analysis stage aims to find differences between the process models of different organizations. In this thesis study mismatch patterns defined in \cite{dijkman2007mismatch} are mathematically defined and analyzers are developed to locate these patterns. At the time of this study, it is known to be first to use mismatch patterns in a generic method, therefore evaluation is based on comparing with well-defined prior similarity metrics.

Structural similarity between process models is presented in \cite{dijkman2011similarity} by the \textit{graph-edit distance} notion. In graph theory, \textit{graph-edit distance} is the minimum number of \textit{graph-edit operations} necessary to get one from graph to another. In the process mining field, \textit{graph-edit operations} are simply node addition, deletion or substitution. In the study \cite{dijkman2011similarity}, both \textit{graph-edit distance} and \textit{graph-edit similarity} definitions are provided with their mathematical background. In this study, mismatch pattern analysis stage is evaluated by comparing the number of mismatch patterns and the \textit{graph-edit similarity} of process models. Without any performance indicator clustering, it is expected to have larger number of mismatch patterns when the similarity between process models is low. This will ensure the performance and suitability using mismatch pattern analysis instead in the methodology.

 % BartHompes paketi ile ikili ikili çalıştır- run

\subsection{Recommendation Generation}
\label{subsec:recommendation-generation-eval}
In the recommendation generation stage, set of mismatch patterns are presented to the end user based on the selected organization and performance difference threshold. This stage aims to list whole mismatch patterns that can cause the other organizations perform better than a difference threshold. Idea of using performance threshold should be evaluated in this stage with its responsiveness. In other words, it is expected that this stage will help the end user to focus on the most important performance improvements for the organization analyzed. Therefore, different threshold values will be tried to check how many mismatch patterns are generated for organizations and how they could be used for focused analysis. In addition, quality and applicability of the recommendations should be analyzed and this requires a high level of knowledge starting from the collecting event logs in the organizations. This knowledge should include know-how about process changes, domain knowledge about the field of organizations' activity and structural attributions of the organizations.

\section{Experiments}
\label{sec:experiments}


\subsection{LOOAN}
\label{subsec:xx}
* Event log statistics
* Methodology Stages
* Results

-> coselog

\section{Discussions}
\label{sec:discussions}