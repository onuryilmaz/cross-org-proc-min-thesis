* Welcome to you all, my name is Onur Yılmaz and today I will present my thesis study which is named as Recommendation Generation for Performance Improvement by using Cross-Organizational Process Mining. 
* Let me introduce myself a little, I have graduated from Industrial Engineering and Computer Engineering departments of this university and I have worked in BPM and military projects at MilSOFT. For the last year I am working at SAP as a software developer and this year I am planning to complete my master’s degree.
* This is my outline and let me start quickly with the introduction part.
* First of all, what is process mining? Process mining is a young research field where the main idea is to discover, monitor and improve processes with the information hidden in the event logs. Main drivers of process mining are huge amount of available event logs and competitive business life.
* When we look at the Cross-Organizational Process Mining, as cloud computing and shared infrastructures become popular, there are event logs of multiple organizations available today. So how this field can help you? Firstly it helps you to analyze the big picture when you and other organizations work together to execute the same process. Secondly, it can help you to learn from each other when you execute the processes on a shared infrastructure.
* When we look at the focus of this study, a hybrid approach that uses different subfields of process mining is proposed and cross organizational process mining is used where processes are executed on several organizations with the aim of unsupervised learning based on performances of organizations.
* Let's check the related studies in the literature
* This diagram shows the spectrum of process mining with a metaphor of cartography and navigation. These grouped activities, which are subfields of process mining, try to build a bridge between event logs and process models. Within this metaphor, you can think our approach as analyzing multiple cars on the road and discovering their paths. In addition we will check how well they are doing on their paths and create recommendations from their navigation applications.
* When we list the contributions of this study, a cross-organizational process mining approach is developed for performance improvement. Generic and noise capable mining method is used and organizations are clustered based on their performances unlike the studies in the literature based on process structures.
* In addition, mismatch patterns are formulated and analyzers are developed to spot differences and recommendation generation is done to show how organizations can learn from each other. Finally, all these efforts are developed as open-source plugins in ProM framework.
* Now let me present the building bricks of our methodology.
* Firstly, event logs are outputs of ERP or BPM systems and they look like this, series of cases and events with attributes. Or in a more structured way you can check process, cases and events. 
* On the other hand, we have process models with different notations. Workflow nets, for example, are petri nets with start and end nodes and connectedness properties and they have a strong mathematical background. When we look at more business oriented notations, we have BPMN which is a standard and it has aim of easily being understood by stakeholders.
* For process discovery, there are various different approaches proposed with different challenges. In this study, I have focused on Inductive Mining methods and Inductive Miner Infrequent implementation since they can handle noise in the event logs with re-discoverability property.
* When we look at how performances of processes are calculated, the idea is running event logs over the process models with the help of moves in event logs and process models. However, they are not always fitting to each other and we need an alignment which leads us to distance functions and finding optimal alignments. When we successfully aligned event logs over process models we can gather the performance data easily.
* Mismatch patterns, which are differences between process models, are proposed in the literature within three groups of Authorization, Activity and Control Flow. Let me present the ones related to our study.
* Skipped Activity is a pattern of activity that an organization do not undertake at all. On the other hand, refined activity is a pattern where instead of an activity you have a set of activities in another organization.
* For control flows, you can undertake activities at different orders or with different occurrence conditions. Likewise, you can have different dependencies for same activity sets or as a subset you may have additional dependencies.
* Now, I will present the methodology proposed in this thesis study. 
* It is a four-stage approach and firstly process models of organizations are mined. Secondly, performance values are calculated and organizations are clustered with this information. Thirdly, mismatch patterns are found between organizations and clusters. Finally, recommendations are proposed with the generated information. When we look at as a process flow, we will create process models, then clusters and mismatch data here to generate recommendations. 
* Firstly, process model mining gets a noise threshold from user and creates process models for each organization.
* Secondly, performance indicator analysis consists of two stages as replaying and calculating and then clustering. So what performance indicators are used? Two essential performance indicators are used in this study which are average time between activities and standard deviation of time between activities. Organizations want to minimize both to increase throughput and increase stability of plans.
* For replaying, we need some alignment related configuration from user and our plugins in addition to event logs and process models to create performance analysis data for each organization. With these data, we cluster organizations with the cluster number of 1 to N, number of organizations and make the user select "k" by providing within-SSE values.
* For the mismatch patterns, all workflow nets of organizations are converted to BPMN models since mismatch patterns are more appropriate to BPMN notation. with these models, we run each mismatch pattern analyzer for between any two activities. In other words, we can say that give me the differences between activities A and B for organizations X and Y.
* In the last stage, we will create recommendations compared to the organizations that are performing better. Our recommendation will be a tuple of organization, start and end activity and a set of mismatch patterns.
* When we look at the approach completely, we are at the end with cluster analysis data and mismatch patterns data, we get a final parameter from user to set a performance difference threshold. This makes user to say that "give me the learning opportunities with the 20 percent performance increase" for example.
* Lets check the pseudo code of our recommendation generator. We are getting the cluster of our organization and go over all other clusters if they have a data point with the same start and end activity. If they have and they operating better than the threshold, we are calling mismatch pattern analyzers and package them in recommendations.
* Now I will present the results of this approach. 
* To evaluate the approach, evaluation metrics are defined for each stage. For the mining stage we will use fitness and appropriateness from the literature. For performance analysis, we will use alignment costs and internal clustering metrics. For mismatch patterns, since its their first implementation, we will compare with the well-known similarity metrics in the literature. Finally, we will check the responsiveness and degree of helping our users to focus on learning opportunities in the last stage.
* Unfortunately, there are not so many datasets for cross-organizational mining and two datasets are used in this study. First one is a synthetically generated and includes 4 variants. Second one is a real life event log from Coselog project and includes event logs of municipalities in Netherlands.
* First dataset, loan application process have nearly five hundreds cases and more than two thousand events and variants in the dataset are used as organizational logs.
* In the first stage, we mine the process models of these organizations and you can check the process models and high fitness and appropriateness values.
* In the second stage, we cluster these organizations as one, two and four vs three.
* When we cross-compare any two organizations, our mismatch pattern analyzers find differences in accordance with graph-edit similarity values.
* When we create recommendations with 10, 25 and 40 percent of performance increase we can check the responsiveness. This gray line shows the number of mismatch patterns without any performance related clustering. When we cluster organizations, for instance for variant four, there are 5 exact start-end activities that it can enhance their processes. And on average ten mismatch patterns to check when compared to twenty-five or thirty in this range.
* Let me do the same analysis on a real life dataset. Now, we have more than one thousand cases and two thousand events after preprocessing. And these municipalities will be used as organizations.
* When we mine the process models, they have very huge process models and these are 10 to 20 times simplified versions. You can see high fitness and relatively high appropriateness values except municipalities four and five.
* When we cluster them, they are not very well separated into two clusters but for three clusters they separated better.
* When we compare any two municipality for mismatch patterns, we see that except municipalities 4 and 5 we find results in accordance with graph-edit similarity.
* When we check the number of mismatch patterns recommended for municipalities, again this gray line shows the total number of mismatch patterns to analyze if you check organizations one by one. When we cluster, for example for twenty-five percent performance increase you will only need to check six exact start-end activities and they have only 6 mismatch patterns on average. When compared this three-hundred range here it shows that this approach significantly helps user to focus.
* When we collect the results together, we can say that mismatch patterns work in accordance with similarity metrics but information value of each pattern is not equal.
* Recommendation generation helps to focus on differences three times less in a small dataset and nearly one hundred times less in a real-life dataset.
* Finally, recommended patterns could be very important or infeasible in that business environment which needs case and business related assessment. Let me present some insights about these results.
* For the first dataset, variant four performs better between these activities. When we draw the process models between these activities, our results show that there are refined activities and different orders. 
* When we check the real-life event logs, municipality three performs worse between these coded activities. Again I draw the simplified models between these activities. You can see the listed mismatch patterns as different dependencies and orders here. It is impossible to visually and manually locate these differences in big datasets like this one.
* I will conclude now, a cross-organizational process mining approach is presented for performance improvement with unsupervised learning and results show that it is possible to use cross-organizational process mining and mismatch patterns. A four-stage approach and their results are also presented. 
* When we look at the potential future work, different mining techniques can be introduced as well as new performance indicators for business environment and needs. In addition, new mismatch patterns can be introduced and finally domain and BPM expertise can be utilized to assess the quality of recommendations.
* Now I will present a short demonstration on ProM, which is a widely accepted framework. Our plugins for each methodology stage are packaged and included in ProM and also published as open-source. There are five plugins and utilization libraries with internal and external dependencies as diagrammed. Let me show the demonstration which is also available on YouTube.
* Demonstration
* These are my references for this presentation and thank you for your attention.
